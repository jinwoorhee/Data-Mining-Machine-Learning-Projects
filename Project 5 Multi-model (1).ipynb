{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc53c9d",
   "metadata": {
    "id": "6dc53c9d"
   },
   "source": [
    "# Project # 5 - Multi-model\n",
    "Data file: https://raw.githubusercontent.com/vjavaly/Baruch-CIS-STA-3920/main/data/Framingham_4000.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb8bf0-835b-416b-8bac-c6804eedb697",
   "metadata": {
    "id": "7bfb8bf0-835b-416b-8bac-c6804eedb697"
   },
   "source": [
    "## Project #5 Requirements\n",
    "* Load and examine data\n",
    "* Prepare data for model training\n",
    "  * Perform the necessary steps that we learned during the semester\n",
    "* Train 3 separate models\n",
    "  * From the various Classification algorithms that we learned during the semester, train 3 different Classification algorithms\n",
    "* Print accuracy of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efeb609-d6a8-4244-9685-dab384c7e3e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5efeb609-d6a8-4244-9685-dab384c7e3e1",
    "outputId": "bf74a6b4-c230-453a-f9f7-540c9a615b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 12/08/23 11:41:19\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f'Run time: {datetime.now().strftime(\"%D %T\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63b2d6",
   "metadata": {
    "id": "5f63b2d6"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55476c4",
   "metadata": {
    "id": "f55476c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Add all other necessary imports below\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3344a",
   "metadata": {
    "id": "07b3344a"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005676ff-944e-49f8-89fd-24949471e1fb",
   "metadata": {
    "id": "005676ff-944e-49f8-89fd-24949471e1fb"
   },
   "source": [
    "The goal of the Framingham_1.csv dataset is to predict whether the patient has a 10-year risk of future (CHD) coronary heart disease.  \n",
    "The dataset contains:\n",
    "* over 4,000 records\n",
    "* 15 features (independent variables)\n",
    "* the target variable (dependent variable) is 'TenYearCHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cc1068",
   "metadata": {
    "id": "d0cc1068"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/vjavaly/Baruch-CIS-STA-3920/main/data/Framingham_4000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82bfde7",
   "metadata": {
    "id": "e82bfde7"
   },
   "source": [
    "### Examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c59f675",
   "metadata": {
    "id": "3c59f675"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0bbf1-2c10-4cc8-9c88-638f49466a92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52b0bbf1-2c10-4cc8-9c88-638f49466a92",
    "outputId": "75c479c0-d8eb-4d0c-abba-d6d196e17e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
      "0     0   37        4.0              0         0.0     0.0                0   \n",
      "1     0   54        3.0              0         0.0     0.0                0   \n",
      "2     0   50        2.0              0         0.0     1.0                0   \n",
      "3     0   52        3.0              0         0.0     0.0                0   \n",
      "4     1   45        3.0              1        30.0     0.0                0   \n",
      "\n",
      "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
      "0             0         0    169.0  104.0   66.0  20.84       70.0     72.0   \n",
      "1             1         0    227.0  168.0   94.0  22.70       75.0     70.0   \n",
      "2             1         0    241.0  132.0   85.0  23.81       55.0     84.0   \n",
      "3             0         0    325.0  119.5   86.0  24.56       64.0      NaN   \n",
      "4             1         0    233.0  147.0  101.0  24.32       75.0     99.0   \n",
      "\n",
      "   TenYearCHD  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4000 non-null   int64  \n",
      " 1   age              4000 non-null   int64  \n",
      " 2   education        4000 non-null   float64\n",
      " 3   currentSmoker    4000 non-null   int64  \n",
      " 4   cigsPerDay       4000 non-null   float64\n",
      " 5   BPMeds           4000 non-null   float64\n",
      " 6   prevalentStroke  4000 non-null   int64  \n",
      " 7   prevalentHyp     4000 non-null   int64  \n",
      " 8   diabetes         4000 non-null   int64  \n",
      " 9   totChol          3953 non-null   float64\n",
      " 10  sysBP            4000 non-null   float64\n",
      " 11  diaBP            4000 non-null   float64\n",
      " 12  BMI              3982 non-null   float64\n",
      " 13  heartRate        4000 non-null   float64\n",
      " 14  glucose          3628 non-null   float64\n",
      " 15  TenYearCHD       4000 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 500.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739b1218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "739b1218",
    "outputId": "acfeeb0c-23bc-492b-9559-72a7cc1936bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male                 0\n",
      "age                  0\n",
      "education            0\n",
      "currentSmoker        0\n",
      "cigsPerDay           0\n",
      "BPMeds               0\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             47\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 18\n",
      "heartRate            0\n",
      "glucose            372\n",
      "TenYearCHD           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055e644-8cdd-464b-9294-830aa3ab8c69",
   "metadata": {
    "id": "7055e644-8cdd-464b-9294-830aa3ab8c69"
   },
   "source": [
    "### Prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa61de2c",
   "metadata": {
    "id": "aa61de2c"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae6807a-3705-41f2-aae0-abc34215a447",
   "metadata": {
    "id": "bae6807a-3705-41f2-aae0-abc34215a447"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = df.drop('TenYearCHD', axis=1)\n",
    "target = df['TenYearCHD']\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1c0abd6-0431-4131-8326-635e8bf8ea70",
   "metadata": {
    "id": "f1c0abd6-0431-4131-8326-635e8bf8ea70"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718c9324-1947-4d54-87ec-20131c3e7d86",
   "metadata": {
    "id": "718c9324-1947-4d54-87ec-20131c3e7d86"
   },
   "outputs": [],
   "source": [
    "# def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469d556-ccf7-401a-ad81-bad4743a380e",
   "metadata": {
    "id": "5469d556-ccf7-401a-ad81-bad4743a380e"
   },
   "source": [
    "### Display first 100 rows of final dataframe used for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2c39df-8cbf-41d1-aac9-fc0a4dbda4c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e2c39df-8cbf-41d1-aac9-fc0a4dbda4c6",
    "outputId": "e80c6ef1-3947-456f-a882-980ff4e3de7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 Rows of Final Dataframe for Model Training:\n",
      "        male       age  education  currentSmoker  cigsPerDay    BPMeds  \\\n",
      "0  -0.893368 -1.469930   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "1  -0.893368  0.517078   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "2  -0.893368  0.049546   0.023590      -0.973460   -0.754345  5.612085   \n",
      "3   1.119360 -0.534868   1.001616       1.027264    1.762853 -0.178187   \n",
      "4  -0.893368 -0.534868   1.001616       1.027264   -0.083092 -0.178187   \n",
      "5  -0.893368 -0.885516   0.023590       1.027264    0.084721 -0.178187   \n",
      "6  -0.893368  0.750843   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "7  -0.893368  0.633960  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "8   1.119360 -0.067336   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "9  -0.893368 -0.651750   0.023590       1.027264    0.084721 -0.178187   \n",
      "10 -0.893368  0.400195   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "11 -0.893368 -0.301102   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "12 -0.893368  0.517078   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "13 -0.893368 -0.067336   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "14 -0.893368 -0.067336   1.001616       1.027264   -0.418719 -0.178187   \n",
      "15 -0.893368  0.633960   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "16 -0.893368 -1.353047   0.023590       1.027264    1.762853 -0.178187   \n",
      "17  1.119360 -0.184219   0.023590       1.027264    0.923787 -0.178187   \n",
      "18 -0.893368 -0.885516  -0.954436       1.027264    0.923787 -0.178187   \n",
      "19 -0.893368  1.802789  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "20  1.119360 -0.534868  -0.954436       1.027264   -0.670439 -0.178187   \n",
      "21 -0.893368 -0.885516   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "22  1.119360  0.984609  -0.954436       1.027264    0.923787 -0.178187   \n",
      "23  1.119360  0.400195   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "24  1.119360 -1.469930   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "25  1.119360 -1.469930   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "26  1.119360 -0.885516  -0.954436       1.027264   -0.334812 -0.178187   \n",
      "27 -0.893368  0.633960  -0.954436       1.027264    0.923787 -0.178187   \n",
      "28  1.119360 -0.768633   1.979642       1.027264    2.853639 -0.178187   \n",
      "29  1.119360  0.633960  -0.954436       1.027264   -0.334812 -0.178187   \n",
      "30  1.119360 -1.236165  -0.954436       1.027264   -0.334812 -0.178187   \n",
      "31  1.119360 -0.885516   0.023590       1.027264    0.923787 -0.178187   \n",
      "32 -0.893368 -1.469930  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "33  1.119360 -0.885516  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "34 -0.893368 -1.002399   1.001616       1.027264    0.504254 -0.178187   \n",
      "35 -0.893368 -1.119282   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "36  1.119360 -0.651750   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "37 -0.893368  1.101492   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "38 -0.893368 -0.184219  -0.954436       1.027264   -0.670439 -0.178187   \n",
      "39 -0.893368 -0.651750   0.023590       1.027264   -0.502626 -0.178187   \n",
      "40 -0.893368 -0.417985  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "41  1.119360 -1.353047   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "42  1.119360  1.101492   1.001616       1.027264    0.923787 -0.178187   \n",
      "43 -0.893368  1.218375  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "44  1.119360  1.218375  -0.954436       1.027264    0.923787 -0.178187   \n",
      "45 -0.893368  0.750843   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "46  1.119360 -0.534868   1.979642       1.027264   -0.334812 -0.178187   \n",
      "47  1.119360 -0.184219   1.979642       1.027264    1.343320 -0.178187   \n",
      "48  1.119360 -1.236165  -0.954436       1.027264    0.923787 -0.178187   \n",
      "49 -0.893368 -0.417985  -0.954436       1.027264    2.853639 -0.178187   \n",
      "50 -0.893368 -1.119282   0.023590       1.027264    0.923787 -0.178187   \n",
      "51 -0.893368 -0.301102   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "52  1.119360  0.517078  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "53  1.119360  0.166429  -0.954436       1.027264    2.601919 -0.178187   \n",
      "54  1.119360  0.517078   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "55 -0.893368 -1.119282   0.023590       1.027264    0.000814 -0.178187   \n",
      "56 -0.893368 -0.885516   1.001616       1.027264   -0.334812 -0.178187   \n",
      "57 -0.893368  0.049546   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "58 -0.893368 -0.885516   1.001616       1.027264    1.762853 -0.178187   \n",
      "59 -0.893368 -0.885516   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "60 -0.893368  0.049546   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "61  1.119360 -0.651750   1.001616       1.027264    0.504254 -0.178187   \n",
      "62 -0.893368  2.387203   0.023590      -0.973460   -0.754345  5.612085   \n",
      "63 -0.893368  0.166429  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "64  1.119360  2.153437  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "65 -0.893368 -1.236165   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "66 -0.893368 -0.651750   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "67  1.119360  1.802789  -0.954436       1.027264    0.504254 -0.178187   \n",
      "68  1.119360  0.867726   1.001616       1.027264    0.504254 -0.178187   \n",
      "69 -0.893368 -0.184219  -0.954436       1.027264   -0.418719 -0.178187   \n",
      "70 -0.893368 -1.469930   0.023590       1.027264    0.084721 -0.178187   \n",
      "71  1.119360 -1.353047   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "72 -0.893368 -0.885516  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "73 -0.893368  0.750843  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "74  1.119360  0.400195   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "75 -0.893368 -0.651750   1.979642      -0.973460   -0.754345 -0.178187   \n",
      "76 -0.893368 -1.002399   0.023590       1.027264    0.000814 -0.178187   \n",
      "77  1.119360 -1.703696   0.023590       1.027264    0.923787 -0.178187   \n",
      "78 -0.893368 -0.417985   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "79  1.119360  0.867726  -0.954436       1.027264    2.853639 -0.178187   \n",
      "80  1.119360 -0.417985  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "81 -0.893368  0.750843  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "82 -0.893368 -1.586813   1.001616       1.027264    0.504254 -0.178187   \n",
      "83  1.119360 -0.885516   1.001616       1.027264    0.923787 -0.178187   \n",
      "84  1.119360 -1.703696   0.023590       1.027264    0.923787 -0.178187   \n",
      "85  1.119360  0.984609   0.023590       1.027264    4.280052 -0.178187   \n",
      "86  1.119360  0.166429  -0.954436       1.027264    3.440985 -0.178187   \n",
      "87 -0.893368  0.049546   0.023590       1.027264    0.923787 -0.178187   \n",
      "88  1.119360  0.984609   0.023590       1.027264    0.923787 -0.178187   \n",
      "89  1.119360 -1.119282   1.001616       1.027264    0.923787 -0.178187   \n",
      "90 -0.893368 -1.353047   1.001616       1.027264    0.084721 -0.178187   \n",
      "91 -0.893368  0.867726  -0.954436       1.027264   -0.502626 -0.178187   \n",
      "92 -0.893368  0.400195   0.023590       1.027264    0.923787 -0.178187   \n",
      "93  1.119360 -1.119282  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "94  1.119360  0.984609  -0.954436       1.027264    0.923787 -0.178187   \n",
      "95  1.119360  1.685906   0.023590      -0.973460   -0.754345 -0.178187   \n",
      "96 -0.893368 -0.184219   1.001616       1.027264   -0.502626 -0.178187   \n",
      "97 -0.893368  0.750843   1.001616      -0.973460   -0.754345 -0.178187   \n",
      "98 -0.893368 -1.002399  -0.954436      -0.973460   -0.754345 -0.178187   \n",
      "99 -0.893368 -1.236165  -0.954436       1.027264   -0.334812 -0.178187   \n",
      "\n",
      "    prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
      "0         -0.076525     -0.675859 -0.167992 -1.541710 -1.285957 -1.413831   \n",
      "1         -0.076525      1.479599 -0.167992 -0.225735  1.608521  0.925054   \n",
      "2         -0.076525      1.479599 -0.167992  0.091914 -0.019623  0.173270   \n",
      "3         -0.076525      1.479599 -0.167992 -0.089600  0.658771  1.509775   \n",
      "4         -0.076525     -0.675859 -0.167992 -0.951790 -0.969373 -0.327920   \n",
      "5         -0.076525     -0.675859 -0.167992 -1.450954 -1.240731 -1.079705   \n",
      "6         -0.076525     -0.675859 -0.167992  1.566715 -0.562337  0.340333   \n",
      "7         -0.076525      1.479599 -0.167992  0.137293  0.432640  0.757991   \n",
      "8         -0.076525      1.479599 -0.167992 -0.361870  1.925105  2.052731   \n",
      "9         -0.076525     -0.675859 -0.167992 -0.316492 -1.647767 -1.998552   \n",
      "10        -0.076525      1.479599 -0.167992 -0.407249  2.332141  2.178028   \n",
      "11        -0.076525     -0.675859  5.952675 -0.361870  0.342187  0.925054   \n",
      "12        -0.076525      1.479599 -0.167992  1.884364  1.472843  0.089738   \n",
      "13        -0.076525     -0.675859 -0.167992 -1.087926 -1.376409 -1.372065   \n",
      "14        -0.076525      1.479599 -0.167992 -0.225735  0.794449  0.674459   \n",
      "15        -0.076525      1.479599 -0.167992  0.432253  0.477866 -0.035559   \n",
      "16        -0.076525     -0.675859 -0.167992  0.409564 -0.404046  0.131504   \n",
      "17        -0.076525      1.479599 -0.167992 -0.157667  0.364800  0.507396   \n",
      "18        -0.076525     -0.675859 -0.167992 -0.634141 -1.240731 -1.497363   \n",
      "19        -0.076525     -0.675859 -0.167992  0.205361 -0.607564 -0.578515   \n",
      "20        -0.076525      1.479599 -0.167992  0.908727  0.342187  0.089738   \n",
      "21        -0.076525     -0.675859 -0.167992 -1.110615 -0.449272 -0.662047   \n",
      "22        -0.076525      1.479599 -0.167992  0.409564  0.613544  0.507396   \n",
      "23        -0.076525     -0.675859 -0.167992 -0.997169  0.432640  0.507396   \n",
      "24        -0.076525     -0.675859 -0.167992  0.659145 -1.014600 -0.870876   \n",
      "25        -0.076525     -0.675859 -0.167992 -0.906412 -1.285957 -1.497363   \n",
      "26        -0.076525     -0.675859 -0.167992 -0.906412 -1.376409 -1.037939   \n",
      "27        -0.076525      1.479599 -0.167992 -0.089600 -0.200528  0.925054   \n",
      "28        -0.076525     -0.675859 -0.167992 -0.248424 -0.788468  0.215035   \n",
      "29        -0.076525      1.479599 -0.167992  0.069225  0.116056  1.008586   \n",
      "30        -0.076525      1.479599 -0.167992 -0.225735 -0.019623  0.757991   \n",
      "31        -0.076525     -0.675859 -0.167992 -0.475316 -0.336206  0.298567   \n",
      "32        -0.076525     -0.675859 -0.167992 -0.634141 -1.014600 -0.453217   \n",
      "33        -0.076525     -0.675859 -0.167992  0.477631 -1.014600 -1.163236   \n",
      "34        -0.076525     -0.675859 -0.167992 -0.724898 -0.562337 -0.244388   \n",
      "35        -0.076525      1.479599 -0.167992 -0.747587 -0.471885  0.925054   \n",
      "36        -0.076525     -0.675859 -0.167992 -1.178683 -0.788468 -1.163236   \n",
      "37        -0.076525     -0.675859 -0.167992  0.772591 -0.675403 -1.497363   \n",
      "38        -0.076525     -0.675859 -0.167992 -0.906412 -1.421636 -1.330299   \n",
      "39        -0.076525     -0.675859 -0.167992  0.046536 -1.331183 -1.330299   \n",
      "40        -0.076525      1.479599 -0.167992 -0.838344  0.116056  1.175649   \n",
      "41        -0.076525     -0.675859 -0.167992 -1.972806 -1.059826 -0.662047   \n",
      "42        -0.076525     -0.675859 -0.167992  0.023847 -0.901534 -0.620281   \n",
      "43        -0.076525      1.479599 -0.167992  0.023847  0.070830  0.089738   \n",
      "44        -0.076525      1.479599 -0.167992 -1.519021  2.106010  0.925054   \n",
      "45        -0.076525      1.479599 -0.167992  1.203687  2.377367  2.052731   \n",
      "46        -0.076525      1.479599 -0.167992 -0.225735  1.518069  1.593307   \n",
      "47        -0.076525      1.479599 -0.167992 -0.475316  0.523092 -0.327920   \n",
      "48        -0.076525     -0.675859  5.952675 -0.951790 -1.195505 -0.244388   \n",
      "49        -0.076525     -0.675859 -0.167992  0.568388 -0.517111 -0.411452   \n",
      "50        -0.076525     -0.675859 -0.167992 -0.361870 -1.783445 -1.706192   \n",
      "51        -0.076525     -0.675859 -0.167992  0.114604  0.568318  0.382099   \n",
      "52        -0.076525      1.479599 -0.167992  0.681834  0.703997  0.799757   \n",
      "53        -0.076525     -0.675859 -0.167992  0.613767 -0.607564 -0.077325   \n",
      "54        -0.076525      1.479599 -0.167992 -0.271113  0.093443  0.799757   \n",
      "55        -0.076525     -0.675859 -0.167992 -0.997169 -1.240731 -1.915021   \n",
      "56        -0.076525     -0.675859 -0.167992 -1.927427 -0.471885 -0.578515   \n",
      "57        -0.076525     -0.675859 -0.167992  0.296117 -1.059826 -1.079705   \n",
      "58        -0.076525     -0.675859 -0.167992 -0.429938 -0.290980  0.340333   \n",
      "59        -0.076525     -0.675859 -0.167992 -0.498006 -0.969373 -0.912641   \n",
      "60        -0.076525      1.479599 -0.167992 -0.293803  0.749223  0.590928   \n",
      "61        -0.076525     -0.675859 -0.167992  2.338148 -0.336206 -0.411452   \n",
      "62        -0.076525      1.479599 -0.167992 -0.134978  0.161282  0.089738   \n",
      "63        -0.076525     -0.675859 -0.167992  0.205361  0.116056 -0.077325   \n",
      "64        -0.076525     -0.675859 -0.167992  0.001157 -0.110075 -1.747957   \n",
      "65        -0.076525     -0.675859 -0.167992  0.091914 -1.240731 -0.662047   \n",
      "66        -0.076525     -0.675859 -0.167992 -0.543384 -0.290980 -0.578515   \n",
      "67        -0.076525      1.479599 -0.167992 -0.407249  0.703997  0.590928   \n",
      "68        -0.076525     -0.675859  5.952675  0.182671 -0.019623 -0.494983   \n",
      "69        -0.076525     -0.675859 -0.167992  0.364185 -0.562337 -0.453217   \n",
      "70        -0.076525     -0.675859 -0.167992 -0.452627 -1.014600 -0.369686   \n",
      "71        -0.076525     -0.675859 -0.167992 -0.384560 -0.471885 -0.202623   \n",
      "72        -0.076525     -0.675859 -0.167992  0.091914 -0.630177 -0.202623   \n",
      "73        -0.076525      1.479599 -0.167992  0.568388  0.794449  0.507396   \n",
      "74        -0.076525     -0.675859  5.952675 -0.066910 -0.878921 -1.246768   \n",
      "75        -0.076525     -0.675859 -0.167992 -0.724898 -1.059826 -0.829110   \n",
      "76        -0.076525     -0.675859 -0.167992  0.976794 -0.155301  0.507396   \n",
      "77        -0.076525     -0.675859 -0.167992 -0.316492 -0.200528 -0.077325   \n",
      "78        -0.076525     -0.675859 -0.167992  0.228050 -0.788468 -0.996173   \n",
      "79        -0.076525      1.479599 -0.167992 -1.178683  0.070830  0.632693   \n",
      "80        -0.076525      1.479599 -0.167992  2.065878 -0.110075  0.298567   \n",
      "81        -0.076525     -0.675859 -0.167992  0.500321  0.251735  0.340333   \n",
      "82        -0.076525     -0.675859 -0.167992 -0.792966 -1.218118 -1.330299   \n",
      "83        -0.076525     -0.675859 -0.167992 -0.157667 -0.924147 -1.413831   \n",
      "84        -0.076525     -0.675859 -0.167992 -0.838344 -0.064849  0.340333   \n",
      "85        -0.076525      1.479599 -0.167992  0.296117  0.794449  1.175649   \n",
      "86        -0.076525     -0.675859 -0.167992  2.224702 -0.313593  0.925054   \n",
      "87        -0.076525     -0.675859 -0.167992  0.863348 -0.426659  0.006206   \n",
      "88        -0.076525     -0.675859 -0.167992  0.409564  0.161282  0.215035   \n",
      "89        -0.076525     -0.675859 -0.167992  0.250739  0.183895 -0.411452   \n",
      "90        -0.076525     -0.675859 -0.167992 -0.770277 -1.466862 -1.079705   \n",
      "91        -0.076525     -0.675859 -0.167992 -0.044221 -0.268367 -0.244388   \n",
      "92        -0.076525     -0.675859 -0.167992  0.069225 -0.064849 -0.077325   \n",
      "93        -0.076525      1.479599 -0.167992  0.636456  0.048217 -0.119091   \n",
      "94        -0.076525     -0.675859 -0.167992 -1.201372 -0.223141 -1.079705   \n",
      "95        -0.076525     -0.675859 -0.167992 -0.611452 -0.562337 -1.246768   \n",
      "96        -0.076525     -0.675859 -0.167992  0.205361 -0.155301  0.256801   \n",
      "97        -0.076525      1.479599 -0.167992  1.135619  0.817062  0.925054   \n",
      "98        -0.076525      1.479599 -0.167992 -0.180356  0.794449  0.507396   \n",
      "99        -0.076525     -0.675859 -0.167992 -0.021532 -0.675403 -0.996173   \n",
      "\n",
      "         BMI  heartRate   glucose  TenYearCHD  \n",
      "0  -1.217145  -0.476804 -0.413622           0  \n",
      "1  -0.760108  -0.060380 -0.496868           0  \n",
      "2  -0.487360  -1.726076  0.085854           0  \n",
      "3  -0.362043  -0.060380  0.710199           0  \n",
      "4  -0.632334   0.855753  0.127477           0  \n",
      "5  -0.937025  -1.309652 -0.122261           0  \n",
      "6  -0.101581   0.522614  0.085854           0  \n",
      "7   1.092612  -0.476804  0.127477           0  \n",
      "8   0.043393  -1.059798 -0.163884           0  \n",
      "9  -0.484903  -0.726658  0.210723           0  \n",
      "10 -0.752736   0.356044 -0.371999           1  \n",
      "11  0.748606   0.356044  0.127477           0  \n",
      "12  3.075563   0.356044  0.710199           0  \n",
      "13 -0.470160  -0.476804 -0.496868           0  \n",
      "14 -0.366958   1.022323  0.044231           0  \n",
      "15 -0.487360   1.188893  0.335592           0  \n",
      "16 -0.113867   0.106190  0.252346           0  \n",
      "17 -0.602848  -0.809943 -0.080638           1  \n",
      "18 -0.489817  -0.560089 -0.746606           0  \n",
      "19 -1.465321  -0.060380  3.082710           0  \n",
      "20  0.724034  -0.560089 -0.330376           0  \n",
      "21 -0.303071   1.105608 -0.580114           0  \n",
      "22  0.411971  -0.060380 -0.371999           1  \n",
      "23  0.925523  -0.476804 -0.163884           0  \n",
      "24  0.072879   0.106190 -0.371999           1  \n",
      "25 -0.710964  -1.559507  0.626953           0  \n",
      "26 -0.273584   0.605899 -1.537443           0  \n",
      "27  2.660298   0.356044  0.543707           1  \n",
      "28  0.436543  -0.060380 -0.288753           0  \n",
      "29  0.711748  -0.060380  1.084806           0  \n",
      "30  0.166252  -1.059798 -0.330376           0  \n",
      "31 -0.624962  -0.893228 -1.037967           0  \n",
      "32 -1.932187   0.106190 -0.080638           0  \n",
      "33  0.112194  -1.309652 -0.371999           0  \n",
      "34 -1.258917   0.855753 -0.746606           0  \n",
      "35  0.999239   0.939038  0.002608           0  \n",
      "36 -0.860852  -0.893228  0.002608           0  \n",
      "37 -1.480064  -0.476804  0.293969           1  \n",
      "38 -1.091828   1.022323  0.751822           0  \n",
      "39  0.193281  -0.809943 -0.371999           0  \n",
      "40  2.706985   2.021741  0.626953           0  \n",
      "41 -1.072171  -0.976513 -0.621737           0  \n",
      "42  0.153966  -1.476222 -0.621737           1  \n",
      "43  0.416885   0.356044 -0.663360           0  \n",
      "44  0.178538   1.188893  0.044231           0  \n",
      "45  0.161338   0.522614  0.085854           1  \n",
      "46  0.866551  -1.476222  0.127477           0  \n",
      "47 -0.172840  -0.726658  0.127477           0  \n",
      "48 -0.546332   0.772469  2.083758           0  \n",
      "49 -0.381701  -0.060380 -0.413622           0  \n",
      "50 -1.708582  -0.976513 -0.371999           0  \n",
      "51 -0.929654  -1.476222 -0.371999           0  \n",
      "52  0.193281  -0.060380  0.668576           1  \n",
      "53  0.677347   0.772469 -0.788229           0  \n",
      "54  1.185985   0.189475 -0.538491           0  \n",
      "55 -0.799423  -0.060380  0.127477           0  \n",
      "56 -1.113943   0.772469 -0.163884           0  \n",
      "57 -1.241717  -0.060380 -0.205507           0  \n",
      "58 -0.809252  -0.060380 -0.371999           0  \n",
      "59 -0.101581   0.106190 -1.121213           0  \n",
      "60  1.018897   2.021741  0.127477           0  \n",
      "61  0.151509  -1.642792  0.335592           0  \n",
      "62  1.471019  -1.309652  0.543707           0  \n",
      "63 -0.276042  -0.476804 -0.205507           0  \n",
      "64  1.898570  -1.309652  0.002608           0  \n",
      "65  0.080251  -0.643374  0.210723           0  \n",
      "66 -1.656982   0.772469  0.085854           0  \n",
      "67  0.873923   0.106190  0.626953           1  \n",
      "68 -0.683935   0.022905  5.205483           0  \n",
      "69 -0.310442  -0.476804  0.668576           0  \n",
      "70  1.588964   2.854589  0.085854           0  \n",
      "71 -1.015655  -0.226949 -0.205507           0  \n",
      "72  1.613536   1.605317 -0.288753           0  \n",
      "73  3.542429  -0.060380  0.169100           0  \n",
      "74 -0.244098   0.022905  1.084806           1  \n",
      "75 -2.042760  -0.060380 -1.037967           0  \n",
      "76  3.414655   2.854589 -0.704983           0  \n",
      "77 -1.426006   0.356044 -0.621737           0  \n",
      "78  0.473401   0.522614 -0.538491           0  \n",
      "79  0.485687   0.939038  0.876691           0  \n",
      "80  0.338255  -0.893228  0.002608           0  \n",
      "81  1.213015  -1.309652 -0.288753           0  \n",
      "82 -0.769937   1.188893 -0.788229           0  \n",
      "83 -0.118782   0.356044 -0.538491           0  \n",
      "84 -0.457874  -0.393519 -0.496868           0  \n",
      "85  1.525077  -0.060380 -0.704983           0  \n",
      "86  0.485687   0.356044 -0.621737           0  \n",
      "87 -0.369415   1.188893 -0.746606           0  \n",
      "88 -0.113867   0.522614 -0.829852           0  \n",
      "89 -0.293242   1.188893  0.710199           0  \n",
      "90 -0.752736  -1.059798 -0.080638           0  \n",
      "91 -0.224441   0.605899 -0.413622           0  \n",
      "92 -0.386615  -0.809943 -0.080638           0  \n",
      "93 -0.494731  -0.060380  0.085854           0  \n",
      "94 -0.042609  -2.142500 -0.080638           0  \n",
      "95 -0.251470   0.356044 -0.205507           1  \n",
      "96 -0.185126   0.356044  0.210723           0  \n",
      "97  0.053222  -0.060380  0.710199           0  \n",
      "98  2.525153  -0.060380  0.418838           0  \n",
      "99  0.362827   0.106190 -0.330376           0  \n"
     ]
    }
   ],
   "source": [
    "final_df_for_training = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "final_df_for_training['TenYearCHD'] = target.values\n",
    "print(\"First 100 Rows of Final Dataframe for Model Training:\")\n",
    "print(final_df_for_training.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8efaee",
   "metadata": {
    "id": "1a8efaee"
   },
   "source": [
    "### Train Classification model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb03ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "5bb03ef2",
    "outputId": "bffb5b91-68de-40cd-b814-ca2aa2d97f05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10]}, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10]}, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10]}, scoring='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_params, cv=5, scoring='accuracy')\n",
    "lr_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d8d6a-ca79-407f-a5d1-71793afcff23",
   "metadata": {
    "id": "9b5d8d6a-ca79-407f-a5d1-71793afcff23"
   },
   "source": [
    "### Evaluate Classification model 1 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42b7361-878a-42c4-92e0-5b80044b1e0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a42b7361-878a-42c4-92e0-5b80044b1e0a",
    "outputId": "dac3a94e-e976-42ce-b103-f243d3f165cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1}\n",
      "Cross-validated accuracy for Logistic Regression: 0.8537261698440208\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters for Logistic Regression:\", lr_grid.best_params_)\n",
    "print(\"Cross-validated accuracy for Logistic Regression:\", lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d5dc2-58e7-44d0-bc45-b638ffb25a0d",
   "metadata": {
    "id": "a63d5dc2-58e7-44d0-bc45-b638ffb25a0d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aadaa5cc-fbfa-42c7-be04-3229ff5735d0",
   "metadata": {
    "id": "aadaa5cc-fbfa-42c7-be04-3229ff5735d0"
   },
   "source": [
    "### Train Classification model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca817ae-5271-4495-89d7-6fe5c2178f24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "6ca817ae-5271-4495-89d7-6fe5c2178f24",
    "outputId": "5ea4d936-a087-488b-b376-20165551221b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f4540-8482-4ef7-8dd5-0d19e88b333a",
   "metadata": {
    "id": "1e4f4540-8482-4ef7-8dd5-0d19e88b333a"
   },
   "source": [
    "### Evaluate Classification model 2 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbf301b-cf1b-4da7-a80c-67571ac7861d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcbf301b-cf1b-4da7-a80c-67571ac7861d",
    "outputId": "95f70135-62a9-40a8-d28d-51174471e680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'n_estimators': 200}\n",
      "Cross-validated accuracy for Random Forest: 0.8478336221837088\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters for Random Forest:\", rf_grid.best_params_)\n",
    "print(\"Cross-validated accuracy for Random Forest:\", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5ba1e-f521-4664-9f7f-6be739aee18b",
   "metadata": {
    "id": "a9c5ba1e-f521-4664-9f7f-6be739aee18b"
   },
   "source": [
    "### Train Classification model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdcce972-a8c1-4b5c-b8b6-60785786f012",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "cdcce972-a8c1-4b5c-b8b6-60785786f012",
    "outputId": "3937616d-c5f6-4cb6-821f-a9c72adfdebe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.001, 0.01, 0.1]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.001, 0.01, 0.1]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {'C': [0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1]}\n",
    "svc_grid = GridSearchCV(SVC(), svc_params, cv=5, scoring='accuracy')\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3794f9-7ba6-4644-8d2a-6b81fa889bec",
   "metadata": {
    "id": "ab3794f9-7ba6-4644-8d2a-6b81fa889bec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7a3bd03-d46e-464a-9804-8024d8797d0a",
   "metadata": {
    "id": "e7a3bd03-d46e-464a-9804-8024d8797d0a"
   },
   "source": [
    "### Evaluate Classification model 3 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a14d57-b1b8-4eb3-b83c-cdbb200614fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46a14d57-b1b8-4eb3-b83c-cdbb200614fb",
    "outputId": "0222c117-f1f2-4803-9bb7-2e002e25e1a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVC: {'C': 0.1, 'gamma': 0.001}\n",
      "Cross-validated accuracy for SVC: 0.8492201039861353\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters for SVC:\", svc_grid.best_params_)\n",
    "print(\"Cross-validated accuracy for SVC:\", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63089556-aacd-4b0e-bf3f-519bbf116aae",
   "metadata": {
    "id": "63089556-aacd-4b0e-bf3f-519bbf116aae"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
